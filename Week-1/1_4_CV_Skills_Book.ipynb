{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a1ca69",
   "metadata": {},
   "source": [
    "## ðŸ’» UnpackAI DL201 Bootcamp - Week 1 - Skills: Computer Vision\n",
    "\n",
    "### ðŸ“• Learning Objectives\n",
    "\n",
    "* Conceptualize the concept of Tensors in the context of machine learning and their benefits.\n",
    "* Identifiy the differences of important data structures such as Python lists, Numpy arrays and Pandas DataFrames.\n",
    "\n",
    "### ðŸ“– Concepts map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7d198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install unpackai -qq\n",
    "!git clone https://github.com/unpackAI/DL201.git\n",
    "\n",
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "## Config Variables |\n",
    "\n",
    "#Kaggle config\n",
    "\n",
    "DATA_DIR = Path('/kaggle/working/DL201/data') #uncomment for kaggle\n",
    "IMAGE_DIR = Path('/kaggle/working/DL201/img') #Uncomment for Kaggle\n",
    "\n",
    "#Local Config\n",
    "\n",
    "#DATA_DIR = Path.home()/'Datasets'/'unpackAI'/'DL201'/'data'\n",
    "#IMAGE_DIR = Path('../img') #uncomment for local machine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967d070",
   "metadata": {},
   "source": [
    "### Step 1: Loading the data\n",
    "<hr style=\"border:4px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641aa543",
   "metadata": {},
   "source": [
    "As is always, the question becomes, how do we access our data.\n",
    "\n",
    "How is it stored?\n",
    "\n",
    "Many computer vision data sets are organized in two ways.\n",
    "\n",
    "* As individual files stored in a file tree\n",
    "\n",
    "* With Metadata in a JSON or CSV file containing the file paths and the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e769eb4-201d-4a8d-8d08-2670b4166b8b",
   "metadata": {},
   "source": [
    "\n",
    "### Key Concept: File Paths\n",
    "\n",
    "In addition to indexing, another model for storing information is in what is called a file tree. The root of the file tree is the base directory, which on windows is usually 'C:\\\\' or in linux is just / \n",
    "\n",
    "From this, more files and directories can be organized and found along these trees. This method is useful for organizing files rather than data points because it allows us to keep everything together in relevant baskets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69dca6",
   "metadata": {},
   "source": [
    "### How Large is the dataset?\n",
    "\n",
    "Before downloading the data, it is a good idea to know how large the dataset is because this will affect how you move forward? If it is very large, you may need to consider how it will be stored.\n",
    "\n",
    "You may need to select a sample out of the dataset to work with rather than work with the whole set. This will speed up exploring the data because you won't constantly be waiting for the computer to process the data.\n",
    "\n",
    "This information is usually found online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5abc3c",
   "metadata": {},
   "source": [
    "### How are the images stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a58db0",
   "metadata": {},
   "source": [
    "### Case 1: In a Zip File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f7dfc-cf4d-493b-a218-287f24b5cc01",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Extracting Zip Files\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "Zip files are incredibly common in many areas.\n",
    "\n",
    "For datasets, they serve two primary purposes\n",
    "\n",
    "1. This format bundles together many files into one and makes it easier and faster to send it over the internet. Network protocols are similar to the mail. It's much less complicated to send a shipping container rather than do paperwork and handling of thousands of individual boxes.\n",
    "\n",
    "2. Compression. The other problem is bandwidth. Zip files, along with other formats, can make files smaller which is beneficial because they take up less space on the hard drive. More importantly, this means that we can download the dataset faster. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce86a1-eebd-43da-ac82-21ad91e3f59d",
   "metadata": {},
   "source": [
    "##### Step 1: Find the exact file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30fe871-6b00-4c68-91b1-eda2d4fbb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the file path using pathlib\n",
    "\n",
    "emotionsImagesZipPath = DATA_DIR/'CV'/'Emotions_Images_Sample.zip'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96b891-2205-4755-b138-20ad8aa07096",
   "metadata": {},
   "source": [
    "##### Step 2: Unzip the files\n",
    "\n",
    "In this code, we are using a library called shutil\n",
    "Shutil is short for shell utility.\n",
    "\n",
    "This allows python to make commands in the shell like we learned earlier.\n",
    "\n",
    "In this case, we are telling it to unzip a file at location X and put it into location Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e085b961-8e37-4a42-a67f-79d70fb2d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzipping Zip files in Python\n",
    "import os\n",
    "from shutil import unpack_archive\n",
    "\n",
    "unpack_archive(emotionsImagesZipPath,DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41a79c-5faa-4508-ad46-ac3832be37e2",
   "metadata": {},
   "source": [
    "##### Step 3: Check the file path\n",
    "\n",
    "\n",
    "\n",
    "Now that we extracted the data, we now need to make sure that we know where our data is, and check up on it before proceeding to the next level.\n",
    "\n",
    "Check the output of the next command and see what it is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d64997-3b4a-4804-92cf-d184307a8283",
   "metadata": {},
   "source": [
    "Now that we have unzipped our dataset, we can proceed to see \n",
    "what is inside of it. We should look for our labels first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ca79b",
   "metadata": {},
   "source": [
    "Now that we have unzipped our dataset, we can proceed to see \n",
    "what is inside of it. We should look for our labels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9389a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS_IMAGES_DIR = DATA_DIR/'Emotions_Images_Sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28104b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(EMOTIONS_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843db8b",
   "metadata": {},
   "source": [
    "Here, the labels are conveniently stored as directory names, so they are easy to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b01b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fear', 'Angry', 'Neutral', 'Surprise', 'Happy', 'Sad', 'Disgust']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b938af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c59f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of labels: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'total number of labels: {len(labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad67ba",
   "metadata": {},
   "source": [
    "### How are the Classes Structured?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dae53d",
   "metadata": {},
   "source": [
    "There are two common places to extract the labels from. The first is from the directory structure.\n",
    "\n",
    "The second is from the file paths themselves.\n",
    "\n",
    "And the third is that it is located in a metadata file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d54d0",
   "metadata": {},
   "source": [
    "### Are the Images Stored in a File Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9296f9",
   "metadata": {},
   "source": [
    "If the files are stored in a directory structure, then the labels will be the names of the directories, and the file paths for each image will be inside of those directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdbf4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: (Fear) contains 51 instances\n",
      "Class: (Angry) contains 51 instances\n",
      "Class: (Neutral) contains 51 instances\n",
      "Class: (Surprise) contains 101 instances\n",
      "Class: (Happy) contains 51 instances\n",
      "Class: (Sad) contains 51 instances\n",
      "Class: (Disgust) contains 51 instances\n"
     ]
    }
   ],
   "source": [
    "instancesPerClassDict = {}\n",
    "\n",
    "filepathDictionary = {}\n",
    "\n",
    "for label in os.listdir(EMOTIONS_IMAGES_DIR):\n",
    "    \n",
    "    # This gives us a label for each bit of code\n",
    "    imagesDirectory = EMOTIONS_IMAGES_DIR/label\n",
    "    \n",
    "    # This code gives a list of all the images in the directory\n",
    "    \n",
    "    images = os.listdir(imagesDirectory)\n",
    "    for fileName in images:\n",
    "        \n",
    "        imagePath = imagesDirectory/fileName # makes a longer path\n",
    "        \n",
    "        imageName = imagePath \n",
    "    \n",
    "    instancesPerClassDict[label] = len(images)\n",
    "    \n",
    "for key, value in instancesPerClassDict.items():\n",
    "    print(f'Class: ({key}) contains {value} instances')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef08de",
   "metadata": {},
   "source": [
    "Now, we have our data in a format that it can be put into a fastAI model to give us more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11360702",
   "metadata": {},
   "source": [
    "### Are the Labels and File Paths Stored in a Metadata File?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fcdcb",
   "metadata": {},
   "source": [
    "In some cases, the files may be located on a cloud server, or put together into one large directory. This means that the information is not organized with a file tree, but rather in metadata.\n",
    "\n",
    "This metadata can come as a CSV or a JSON File."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59aacb-d95f-465b-8d0e-48ae6d5b21a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "Type 3: This is the google landmarks image dataset, it contains lots of information on different photos that users have uploaded along with different kinds of metadata.\n",
    "\n",
    "However, the  dataset is quite large, so it makes more sense to download the paths individually\n",
    "\n",
    "These  metadata files contain both the labels and the file paths that we need\n",
    "\n",
    "Step 1, identifying the x and the y \n",
    "\n",
    "The features (x) in this case are the images Labels (y) in this case are the  landmark IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5019e911-6a15-49a9-b4c9-bd21f4df505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of computer vision datasets \n",
    "import os \n",
    "\n",
    "googleLandmarksPath = DATA_DIR/'CV'/'landmarks'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84a7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognition_solution.csv\n",
      "train.csv\n",
      "retrieval_solution.csv\n",
      "boxes_split2.csv\n",
      "index.csv\n",
      "test.csv\n",
      "landmarksample.csv\n",
      "boxes_split1.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This snippet can be useful for handling many csv files\n",
    "\n",
    "for dirname, _, filenames in os.walk(googleLandmarksPath):\n",
    "    for filename in filenames:  # loops through all the files in the directories\n",
    "        print(filename) # Gives a file name, without the complete file path\n",
    "        filepath = os.path.join(dirname,filename) # Completes the file path\n",
    "        filename = filename.split('.')[0] # Removes the file extension for naming\n",
    "        exec(f\"{filename} = pd.read_csv('{filepath}')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3561e98-58cb-4806-9399-4033bd50be07",
   "metadata": {},
   "source": [
    "### Metadata EDA\n",
    "\n",
    "We want to know  the shape, because as we learned in the last lesson, shape is very important.\n",
    "\n",
    "If we check the ratios of the shape and we find relationships, we can confirm that we have what we need\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54229647-5466-458e-9345-deb995579996",
   "metadata": {},
   "source": [
    "Again, we can look at the shape and the size of the datasets. In this, it might be useful to see any relationships between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "092bd43b-467e-4cfc-9b33-fb559f0aa896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638a7921e893de63</td>\n",
       "      <td>http://lh6.ggpht.com/-okvU3kjsKWQ/TjnHZCjgLdI/...</td>\n",
       "      <td>3918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ec108f2c67d28082</td>\n",
       "      <td>https://lh4.googleusercontent.com/-ghGLWnz_5Nw...</td>\n",
       "      <td>4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8b8d9329e3fccd0a</td>\n",
       "      <td>https://lh4.googleusercontent.com/-49VHsrW3voo...</td>\n",
       "      <td>6090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  638a7921e893de63  http://lh6.ggpht.com/-okvU3kjsKWQ/TjnHZCjgLdI/...   \n",
       "1  ec108f2c67d28082  https://lh4.googleusercontent.com/-ghGLWnz_5Nw...   \n",
       "2  8b8d9329e3fccd0a  https://lh4.googleusercontent.com/-49VHsrW3voo...   \n",
       "\n",
       "  landmark_id  \n",
       "0        3918  \n",
       "1        4786  \n",
       "2        6090  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "train.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "print(train.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cfefa",
   "metadata": {},
   "source": [
    "In this dataset, the label is the landmarkID\n",
    "\n",
    "The file location is a little more tricky because it is stored on google's servers, and needs to be downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8ed660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarkLabels = train['landmark_id']\n",
    "landmarkURLs = train['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89615665",
   "metadata": {},
   "source": [
    "Although these are different, the principles remain the same that we need to know what the image is, and where the image is stored. The label and the file path/url will hold this information. Once we have this information, we can then proceed to perform EDA.\n",
    "\n",
    "https://www.kaggle.com/piyushrg/computer-vision-av-fastai/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1feed9",
   "metadata": {},
   "source": [
    "## Coarse Checks\n",
    "<hr style=\"border:4px solid gray\"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9502fe",
   "metadata": {},
   "source": [
    "In order to leverage a fastAI model, the two key pieces of information that we will need to fit the data into the model are the labels, and how the images are stored. \n",
    "\n",
    "Once we can do that, we can go head and train a preliminary model to give more quantified information on how to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b78acb4a-61dc-4d5f-a2c5-e53a47458217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "!pip install -Uqq fastbook[full]\n",
    "\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "#hide\n",
    "from fastbook import *\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9fc60-8198-4441-9857-4dd6eae0e9c3",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "If our data is stored in google colab we can use the following code as a template to  upload it.\n",
    "\n",
    "The goal here is to get the file paths or our x variable (which is the images) along with the y variable which is the label contained in the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "530e71ee-87fa-401d-867b-d0f887131336",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_DATASET_DIR = DATA_DIR/'Emotions_Images_Sample'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f54ad-a821-4186-8099-fe52ee771cef",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Once we have our images in a path, we can use a dataloader to preprocess and transform the data automatically for us using FastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "781c444d-f070-4cab-ace3-ad701098823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaders(GetAttr):\n",
    "  def __init__(self, *loaders): self.loaders = loaders\n",
    "  def __getitem__(self, i): return self.loaders[i]\n",
    "  train,valid = add_props(lambda i, self: self[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40e17212-4cdf-4316-8c32-eb18f641a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = DataBlock (\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter = RandomSplitter(valid_pct=0.2, seed=99),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(225,225)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fe75a35-93b8-457e-adc2-91504afaa059",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = emotions.new(\n",
    "    item_tfms=RandomResizedCrop(28, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8e7a4d1-f5a6-4953-8b47-ac86b034d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = emotions.dataloaders(CV_DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d90b4-88a1-4b01-854f-fba782a6e536",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1c31609-a231-43c9-8113-663e7e69aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bb88384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.183473</td>\n",
       "      <td>3.416628</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.980531</td>\n",
       "      <td>2.600915</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.954985</td>\n",
       "      <td>2.222032</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.955656</td>\n",
       "      <td>2.193115</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.922348</td>\n",
       "      <td>2.174412</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.854110</td>\n",
       "      <td>2.236914</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a20d5",
   "metadata": {},
   "source": [
    "## Part 3: Interpreting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea25e1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8447e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b745f5",
   "metadata": {},
   "source": [
    "### What is the Accuracy of the Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b517b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f04f427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.20      0.12      0.15        16\n",
      "     Disgust       0.40      0.25      0.31        16\n",
      "        Fear       0.18      0.29      0.22         7\n",
      "       Happy       0.20      0.22      0.21         9\n",
      "     Neutral       0.07      0.10      0.08        10\n",
      "         Sad       0.07      0.33      0.12         3\n",
      "    Surprise       0.36      0.20      0.26        20\n",
      "\n",
      "    accuracy                           0.20        81\n",
      "   macro avg       0.21      0.22      0.19        81\n",
      "weighted avg       0.26      0.20      0.21        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2f95b",
   "metadata": {},
   "source": [
    "### What Does the Confusion Matrix Look Like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b60de",
   "metadata": {},
   "source": [
    "interp.confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0fcae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855087b",
   "metadata": {},
   "source": [
    "### Do you see any clear patterns in the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad45a93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b092f975",
   "metadata": {},
   "source": [
    "#### Can you think of reasons why it got confused?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261a2be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a123defb",
   "metadata": {},
   "source": [
    "### What are the Most Confused Images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23be1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a984c3e",
   "metadata": {},
   "source": [
    "#### Should any of these Images be removed from the Dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719681aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d779fa3b",
   "metadata": {},
   "source": [
    "#### Are they Clustered in One or a Few Classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c6ff8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83a2e229",
   "metadata": {},
   "source": [
    "### Are they Distributed across many Classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca171c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6716254d",
   "metadata": {},
   "source": [
    "### Can you find any poor quality images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa0273",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e44e79e",
   "metadata": {},
   "source": [
    "### Can Filters be Applied to Improve the Quality of the Images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117d2f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35050258",
   "metadata": {},
   "source": [
    "### Are any Features Blocked or Occluded in these images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9aaa2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2edb2b28",
   "metadata": {},
   "source": [
    "### Can any Features be Highlighted to Improve the Model's Performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923250a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f2a9df9",
   "metadata": {},
   "source": [
    "### Where Does this First Run Strengthen your Hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ff6dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db1cd0e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a39de08",
   "metadata": {},
   "source": [
    "### Have Any Other Weaknesses in the Model been Revealed? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1bdc7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e237f727",
   "metadata": {},
   "source": [
    "### Are There Any Major Class Inbalances that Affect Model Performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c380e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac289d78",
   "metadata": {},
   "source": [
    "#### Can These be improved by Image Augmentation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609fc6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab1d96ea",
   "metadata": {},
   "source": [
    "### Can you collect more data in areas where your model is weak?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83099029",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc50098",
   "metadata": {},
   "source": [
    "#### Can you Easily Find More Data by Reverse Image Searching the Most Confused Images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1857da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6dd6c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ca27d3",
   "metadata": {},
   "source": [
    "### How Could Image Preprocessing Make Features More Apparent to the Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14808f5c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b35736f271ae3a6547f08ef3ad12296102f5e6031b2a7c6493a7e5cc9f313275"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
