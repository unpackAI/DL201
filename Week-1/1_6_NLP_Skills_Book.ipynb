{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b990127e",
   "metadata": {},
   "source": [
    "## üíª UnpackAI DL201 Bootcamp - Week 1 - Skills: NLP\n",
    "\n",
    "### üìï Learning Objectives\n",
    "\n",
    "* Solidify the basic notion of NLP and how it can be applied to a variety of tasks.\n",
    "* Practice using Pandas for loading and processing text data.\n",
    "* Ilustrate the process of converting a text document into a dataframe and from there into a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2717a57",
   "metadata": {},
   "source": [
    "### A basic NLP Overview\n",
    "\n",
    "From Wikipedia:\n",
    "- \"Natural language processing (NLP) is a subfield of **linguistics, computer science, and artificial intelligence** concerned with the interactions between computers and **human language**, in particular how to program computers to **process and analyze** large amounts of natural language data. The goal is a computer capable of **\"understanding\"** the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\n",
    "\n",
    "- Approaches to NLP tasks:\n",
    "    - Rule-based\n",
    "    - Traditional machine learning\n",
    "    - Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a04c7e",
   "metadata": {},
   "source": [
    "In NLP, we often need to perform text preprocessing, such as removing stop words, stemming, lemmatization, and tokenization.\n",
    "A nice overview is presented in: \n",
    "- https://stanfordnlp.github.io/CoreNLP/ \n",
    "- https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP\n",
    "\n",
    "Common NLP tasks:\n",
    "- Classification\n",
    "- Masked filing\n",
    "- Text prediction\n",
    "- Sentiment analysis\n",
    "    - Positive\n",
    "    - Negative\n",
    "    - Subjectivity\n",
    "- Entity recognition\n",
    "    - Person\n",
    "    - Location\n",
    "    - Organization\n",
    "- Entity extraction\n",
    "- Keyword extraction\n",
    "- Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71e40e",
   "metadata": {},
   "source": [
    "### Ilustrative example\n",
    "\n",
    "Below there is a code example that that illustrates the usage of Pandas for text manipulation and a few exploratory steps to create Tensors representing the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9dbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "! pip install transformers openpyxl\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import requests\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe8f1d",
   "metadata": {},
   "source": [
    "Let's load a sample book conveniently available in txt format from the collection at http://www.textfiles.com/stories/ the book in this case is Aladdin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5340ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample text, from the provided url\n",
    "response = requests.get('http://www.textfiles.com/stories/alad10.txt')\n",
    "sample_text = response.text\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = sample_text.split('\\n')\n",
    "\n",
    "# Load the sentences into a dataframe\n",
    "df = pd.DataFrame(sentences, columns=['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f56a9",
   "metadata": {},
   "source": [
    "As it has been reitared before, loading the data into Pandas gives us tremendous flexibility to perform data cleaning and preprocessing with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8c3329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>bowl, twelve silver plates containing rich mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>desperate deed if I refused to go and ask your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>the Princess.  \"Fear nothing,\" Aladdin said to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>the mountains.  Aladdin was so tired that he b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>passed there. Her mother did not believe her i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aladdin did not mend his ways.  One day, when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>people by her touch of their ailments, whereup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>way and ordered Aladdin to be unbound, and par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>lamp and kill him afterwards.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>more wicked and more cunning than himself.  He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"I am your uncle, and knew you from your liken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>fruit off the trees, and, having got the lamp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>and Aladdin told his mother about the lamp.  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>battles for him, but remained as courteous as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cotton, for he would sell the lamp instead.  A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence\n",
       "94   bowl, twelve silver plates containing rich mea...\n",
       "136  desperate deed if I refused to go and ask your...\n",
       "165  the Princess.  \"Fear nothing,\" Aladdin said to...\n",
       "33   the mountains.  Aladdin was so tired that he b...\n",
       "180  passed there. Her mother did not believe her i...\n",
       "8    Aladdin did not mend his ways.  One day, when ...\n",
       "432  people by her touch of their ailments, whereup...\n",
       "330  way and ordered Aladdin to be unbound, and par...\n",
       "73                     lamp and kill him afterwards.\\r\n",
       "420  more wicked and more cunning than himself.  He...\n",
       "13   \"I am your uncle, and knew you from your liken...\n",
       "60   fruit off the trees, and, having got the lamp,...\n",
       "98   and Aladdin told his mother about the lamp.  S...\n",
       "276  battles for him, but remained as courteous as ...\n",
       "89   cotton, for he would sell the lamp instead.  A..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect some of the sentences\n",
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f93c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the sentences that have less than 3 words\n",
    "df = df[df['sentence'].str.split().str.len() > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f87549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenis\\AppData\\Local\\Temp/ipykernel_10168/4114492291.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['sentence'] = df['sentence'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Aladdin at last prevailed upon her to go befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>carry his request  She fetched a napkin and la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Besides this six slaves beautifully dressed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>treasure Aladdin forgot his fears and grasped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>amazed he could not say a word  Where is your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>and filled up the small house and garden  Alad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>spokesman we cannot find jewels enough  The Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>deserve to be burnt to ashes but that this req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>at nightfall to his mother who was overjoyed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>When the three months were over Aladdin sent h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence\n",
       "117  Aladdin at last prevailed upon her to go befor...\n",
       "118  carry his request  She fetched a napkin and la...\n",
       "221  Besides this six slaves beautifully dressed to...\n",
       "48   treasure Aladdin forgot his fears and grasped ...\n",
       "334  amazed he could not say a word  Where is your ...\n",
       "209  and filled up the small house and garden  Alad...\n",
       "265  spokesman we cannot find jewels enough  The Su...\n",
       "457  deserve to be burnt to ashes but that this req...\n",
       "27   at nightfall to his mother who was overjoyed t...\n",
       "192  When the three months were over Aladdin sent h..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation from all sentences\n",
    "df['sentence'] = df['sentence'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Note: instead of regex a list of punctuation can be used, give it a try!\n",
    "punctuation = [\n",
    "    '.', ',', '!', '?', ':', ';', '\"', \"'\", '-', '_', '(', ')', '[', ']', '{', '}', '#', '@', '$', '%', '^', '&', '*',\n",
    "     '+', '=', '<', '>', '/', '\\\\', '|', '~', '`', '‚Äú', '‚Äù', '‚Äò', '‚Äô'\n",
    "]\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aedee9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>the bed had been carried into some strange hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>her father  his mother on hearing this burst o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>the princess that no man living would come up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>returned aladdin  i wished your majesty to hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>hearing this said there is an old one on the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>another such fearful night and wished to be se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>whom he murdered  he it was who put that wish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>saying i must build a palace fit for her and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>cellar and the princess put the powder aladdin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>him of her sons violent love for the princess ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence\n",
       "179  the bed had been carried into some strange hou...\n",
       "116  her father  his mother on hearing this burst o...\n",
       "198  the princess that no man living would come up ...\n",
       "261  returned aladdin  i wished your majesty to hav...\n",
       "303  hearing this said there is an old one on the c...\n",
       "189  another such fearful night and wished to be se...\n",
       "460  whom he murdered  he it was who put that wish ...\n",
       "229  saying i must build a palace fit for her and t...\n",
       "396  cellar and the princess put the powder aladdin...\n",
       "134  him of her sons violent love for the princess ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all sentences to lowercase\n",
    "df['sentence'] = df['sentence'].str.lower()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bc800",
   "metadata": {},
   "source": [
    "**Sentences are a key unit of information when it comes to NLP** (as wells as tokens) in order to represent our data as a uniform \"block\" of text, we need to find out our longest sentence, the rest of them will later be padded with padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3fdce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length is 76\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the longest senctence\n",
    "max_len = df['sentence'].str.len().max()\n",
    "print(f'max sentence length is {max_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e70bd",
   "metadata": {},
   "source": [
    "The transformers library provides a convenient way to load a variety of BERT models. Let's first load and explore a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6b2c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa75445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is: 30522\n"
     ]
    }
   ],
   "source": [
    "# Get the tokenizer vocabulary words\n",
    "vocab = bert_tokenizer.vocab\n",
    "vocab_size = len(vocab)\n",
    "print(f'vocab size is: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e209cb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12204</th>\n",
       "      <td>encyclopedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>##ized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23141</th>\n",
       "      <td>##firmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13789</th>\n",
       "      <td>cheshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>midst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15755</th>\n",
       "      <td>captains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21536</th>\n",
       "      <td>jing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>–≤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>sprang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20051</th>\n",
       "      <td>##lat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21737</th>\n",
       "      <td>##urne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tokens\n",
       "12204  encyclopedia\n",
       "2853           sold\n",
       "3550         ##ized\n",
       "23141      ##firmed\n",
       "13789      cheshire\n",
       "2730         killed\n",
       "12930         midst\n",
       "15755      captains\n",
       "21536          jing\n",
       "1182              –≤\n",
       "7216        comfort\n",
       "2607         course\n",
       "15627        sprang\n",
       "20051         ##lat\n",
       "21737        ##urne"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary words as a list, load them into a dataframe\n",
    "vocab_list = list(vocab.keys())\n",
    "vocab_df = pd.DataFrame(vocab_list, columns=['tokens'])\n",
    "vocab_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9146db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 995 tokens that begin with \"unused\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>[unused662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>[unused315]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>[unused776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>[unused454]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>[unused754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>[unused905]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>[unused549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[unused256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[unused55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>[unused717]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tokens\n",
       "667  [unused662]\n",
       "320  [unused315]\n",
       "781  [unused776]\n",
       "459  [unused454]\n",
       "759  [unused754]\n",
       "910  [unused905]\n",
       "554  [unused549]\n",
       "261  [unused256]\n",
       "56    [unused55]\n",
       "722  [unused717]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of tokens that begin with 'UNUSED'\n",
    "unused_tokens = vocab_df[vocab_df['tokens'].str.find('unused')>=0]\n",
    "print(f'There are {len(unused_tokens)} tokens that begin with \"unused\"')\n",
    "unused_tokens.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e9effe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 997 tokens that have a size of 1 character\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>·¥∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>Èï∑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>—à</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>‰∫ï</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>„Äú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>‡Æö</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>Â∞á</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>‚±º</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>Ê≥ï</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tokens\n",
       "1492      ·¥∞\n",
       "1967      Èï∑\n",
       "1203      —à\n",
       "1754      ‰∫ï\n",
       "1645      „Äú\n",
       "1383      ‡Æö\n",
       "1828      Â∞á\n",
       "1053      q\n",
       "1631      ‚±º\n",
       "1901      Ê≥ï"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tokens that have a size of 1 character\n",
    "one_char_tokens = vocab_df[vocab_df['tokens'].str.len()==1]\n",
    "print(f'There are {len(one_char_tokens)} tokens that have a size of 1 character')\n",
    "one_char_tokens.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae4e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28042 tokens that likely reprensent English words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20492</th>\n",
       "      <td>##mt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11114</th>\n",
       "      <td>gazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>brewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>draft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>enemy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>potentially</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>gravel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26613</th>\n",
       "      <td>klan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18187</th>\n",
       "      <td>jagged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17587</th>\n",
       "      <td>peterborough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tokens\n",
       "20492          ##mt\n",
       "11114         gazed\n",
       "16005       brewing\n",
       "4433          draft\n",
       "4099          enemy\n",
       "9280    potentially\n",
       "11127        gravel\n",
       "26613          klan\n",
       "18187        jagged\n",
       "17587  peterborough"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tokens which have a size of more than 2 characters and does not contain the word 'unused'\n",
    "two_char_tokens = vocab_df[(vocab_df['tokens'].str.len()>2) & (vocab_df['tokens'].str.find('unused')<0)]\n",
    "print(f'There are {len(two_char_tokens)} tokens that likely reprensent English words')\n",
    "two_char_tokens.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc784c",
   "metadata": {},
   "source": [
    "Each sentence is currently represented as a list of characters. We need to transform this into a list of tokens, tokens then get converted into numbers using the tokenizers vocabulary as indexes. Here is an example with a phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826a1502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample sentence is:\n",
      "This is a sample sentence, which we will tokenize using the BERT tokenizer.\n",
      "\n",
      "The tokenized sentence is:\n",
      "['this', 'is', 'a', 'sample', 'sentence', ',', 'which', 'we', 'will', 'token', '##ize', 'using', 'the', 'bert', 'token', '##izer', '.']\n",
      "\n",
      "The numericalized sentence is:\n",
      "[2023, 2003, 1037, 7099, 6251, 1010, 2029, 2057, 2097, 19204, 4697, 2478, 1996, 14324, 19204, 17629, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Example of tokenizing a sentence\n",
    "sample_sentence = \"This is a sample sentence, which we will tokenize using the BERT tokenizer.\"\n",
    "print(f'The sample sentence is:\\n{sample_sentence}')\n",
    "\n",
    "tokenized_sentence = bert_tokenizer.tokenize(sample_sentence)\n",
    "print(f'\\nThe tokenized sentence is:\\n{tokenized_sentence}')\n",
    "\n",
    "numericalized_sentence = bert_tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "print(f'\\nThe numericalized sentence is:\\n{numericalized_sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79392b66",
   "metadata": {},
   "source": [
    "We should now do the same for the sentences in the dataframe. Before proceding is a good idea to create a copy of what we have so far to be able to revert back to the original dataframe in case we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205585c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the senctences dataframe\n",
    "tokens_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47e1b1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>him of the lamp  he rubbed it and the genie ap...</td>\n",
       "      <td>[him, of, the, lamp, he, rubbed, it, and, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>reality precious stones  he then asked for som...</td>\n",
       "      <td>[reality, precious, stones, he, then, asked, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>replied aladdin  so they sat at breakfast till...</td>\n",
       "      <td>[replied, ala, ##ddin, so, they, sat, at, brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>himself in africa under the window of the prin...</td>\n",
       "      <td>[himself, in, africa, under, the, window, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>treasure aladdin forgot his fears and grasped ...</td>\n",
       "      <td>[treasure, ala, ##ddin, forgot, his, fears, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>the princess that no man living would come up ...</td>\n",
       "      <td>[the, princess, that, no, man, living, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>mine tell me what has become of an old lamp i ...</td>\n",
       "      <td>[mine, tell, me, what, has, become, of, an, ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>stood in a halfcircle round the throne with th...</td>\n",
       "      <td>[stood, in, a, half, ##ci, ##rcle, round, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>hath made us aware of its virtues we will use ...</td>\n",
       "      <td>[hat, ##h, made, us, aware, of, its, virtues, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>people by her touch of their ailments whereupo...</td>\n",
       "      <td>[people, by, her, touch, of, their, ai, ##lm, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "155  him of the lamp  he rubbed it and the genie ap...   \n",
       "86   reality precious stones  he then asked for som...   \n",
       "97   replied aladdin  so they sat at breakfast till...   \n",
       "352  himself in africa under the window of the prin...   \n",
       "48   treasure aladdin forgot his fears and grasped ...   \n",
       "198  the princess that no man living would come up ...   \n",
       "369  mine tell me what has become of an old lamp i ...   \n",
       "214  stood in a halfcircle round the throne with th...   \n",
       "100  hath made us aware of its virtues we will use ...   \n",
       "432  people by her touch of their ailments whereupo...   \n",
       "\n",
       "                                    tokenized_sentence  \n",
       "155  [him, of, the, lamp, he, rubbed, it, and, the,...  \n",
       "86   [reality, precious, stones, he, then, asked, f...  \n",
       "97   [replied, ala, ##ddin, so, they, sat, at, brea...  \n",
       "352  [himself, in, africa, under, the, window, of, ...  \n",
       "48   [treasure, ala, ##ddin, forgot, his, fears, an...  \n",
       "198  [the, princess, that, no, man, living, would, ...  \n",
       "369  [mine, tell, me, what, has, become, of, an, ol...  \n",
       "214  [stood, in, a, half, ##ci, ##rcle, round, the,...  \n",
       "100  [hat, ##h, made, us, aware, of, its, virtues, ...  \n",
       "432  [people, by, her, touch, of, their, ai, ##lm, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize each sentence in the dataframe\n",
    "tokens_df['tokenized_sentence'] = tokens_df['sentence'].apply(bert_tokenizer.tokenize)\n",
    "tokens_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a113239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_sentence</th>\n",
       "      <th>numericalized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>mother that though he consented to the marriag...</td>\n",
       "      <td>[mother, that, though, he, consent, ##ed, to, ...</td>\n",
       "      <td>[2388, 2008, 2295, 2002, 9619, 2098, 2000, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>this stone lies a treasure which is to be your...</td>\n",
       "      <td>[this, stone, lies, a, treasure, which, is, to...</td>\n",
       "      <td>[2023, 2962, 3658, 1037, 8813, 2029, 2003, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>may touch it so you must do exactly as i tell ...</td>\n",
       "      <td>[may, touch, it, so, you, must, do, exactly, a...</td>\n",
       "      <td>[2089, 3543, 2009, 2061, 2017, 2442, 2079, 359...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>reality precious stones  he then asked for som...</td>\n",
       "      <td>[reality, precious, stones, he, then, asked, f...</td>\n",
       "      <td>[4507, 9062, 6386, 2002, 2059, 2356, 2005, 207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and told his mother of his newly found uncle  ...</td>\n",
       "      <td>[and, told, his, mother, of, his, newly, found...</td>\n",
       "      <td>[1998, 2409, 2010, 2388, 1997, 2010, 4397, 217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>aladdin looked up  she called to him to come t...</td>\n",
       "      <td>[ala, ##ddin, looked, up, she, called, to, him...</td>\n",
       "      <td>[21862, 18277, 2246, 2039, 2016, 2170, 2000, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>streets as usual a stranger asked him his age ...</td>\n",
       "      <td>[streets, as, usual, a, stranger, asked, him, ...</td>\n",
       "      <td>[4534, 2004, 5156, 1037, 7985, 2356, 2032, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>cellar and the princess put the powder aladdin...</td>\n",
       "      <td>[cellar, and, the, princess, put, the, powder,...</td>\n",
       "      <td>[15423, 1998, 1996, 4615, 2404, 1996, 9898, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>not but he will use violence  aladdin comforte...</td>\n",
       "      <td>[not, but, he, will, use, violence, ala, ##ddi...</td>\n",
       "      <td>[2025, 2021, 2002, 2097, 2224, 4808, 21862, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>said your father had a brother but i always th...</td>\n",
       "      <td>[said, your, father, had, a, brother, but, i, ...</td>\n",
       "      <td>[2056, 2115, 2269, 2018, 1037, 2567, 2021, 104...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "146  mother that though he consented to the marriag...   \n",
       "46   this stone lies a treasure which is to be your...   \n",
       "47   may touch it so you must do exactly as i tell ...   \n",
       "86   reality precious stones  he then asked for som...   \n",
       "15   and told his mother of his newly found uncle  ...   \n",
       "365  aladdin looked up  she called to him to come t...   \n",
       "9    streets as usual a stranger asked him his age ...   \n",
       "396  cellar and the princess put the powder aladdin...   \n",
       "379  not but he will use violence  aladdin comforte...   \n",
       "16   said your father had a brother but i always th...   \n",
       "\n",
       "                                    tokenized_sentence  \\\n",
       "146  [mother, that, though, he, consent, ##ed, to, ...   \n",
       "46   [this, stone, lies, a, treasure, which, is, to...   \n",
       "47   [may, touch, it, so, you, must, do, exactly, a...   \n",
       "86   [reality, precious, stones, he, then, asked, f...   \n",
       "15   [and, told, his, mother, of, his, newly, found...   \n",
       "365  [ala, ##ddin, looked, up, she, called, to, him...   \n",
       "9    [streets, as, usual, a, stranger, asked, him, ...   \n",
       "396  [cellar, and, the, princess, put, the, powder,...   \n",
       "379  [not, but, he, will, use, violence, ala, ##ddi...   \n",
       "16   [said, your, father, had, a, brother, but, i, ...   \n",
       "\n",
       "                                numericalized_sentence  \n",
       "146  [2388, 2008, 2295, 2002, 9619, 2098, 2000, 199...  \n",
       "46   [2023, 2962, 3658, 1037, 8813, 2029, 2003, 200...  \n",
       "47   [2089, 3543, 2009, 2061, 2017, 2442, 2079, 359...  \n",
       "86   [4507, 9062, 6386, 2002, 2059, 2356, 2005, 207...  \n",
       "15   [1998, 2409, 2010, 2388, 1997, 2010, 4397, 217...  \n",
       "365  [21862, 18277, 2246, 2039, 2016, 2170, 2000, 2...  \n",
       "9    [4534, 2004, 5156, 1037, 7985, 2356, 2032, 201...  \n",
       "396  [15423, 1998, 1996, 4615, 2404, 1996, 9898, 21...  \n",
       "379  [2025, 2021, 2002, 2097, 2224, 4808, 21862, 18...  \n",
       "16   [2056, 2115, 2269, 2018, 1037, 2567, 2021, 104...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the numericalized sentences to the dataframe\n",
    "tokens_df['numericalized_sentence'] = tokens_df['tokenized_sentence'].apply(bert_tokenizer.convert_tokens_to_ids)\n",
    "tokens_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de28c0",
   "metadata": {},
   "source": [
    "Phrases that will be inputted to a BERT model must include the special tokens `[CLS]` and `[SEP]`. These tokens are used to indicate the start and end of the input sequence. Let's add these tokens to the sample phrase. Another special token is `[PAD]`, which is used to pad shorter sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c621a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The tokenized sentence is:\n",
      "['CLS', 'this', 'is', 'a', 'sample', 'sentence', ',', 'which', 'we', 'will', 'token', '##ize', 'using', 'the', 'bert', 'token', '##izer', '.', 'SEP']\n",
      "\n",
      "The numericalized sentence is:\n",
      "[100, 2023, 2003, 1037, 7099, 6251, 1010, 2029, 2057, 2097, 19204, 4697, 2478, 1996, 14324, 19204, 17629, 1012, 100]\n",
      "- The token ID for the special token [CLS] is: 101\n",
      "- The token ID for the special token [SEP] is: 102\n",
      "- The token ID for the special token [PAD] is: 0\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = ['CLS'] + tokenized_sentence + ['SEP']\n",
    "print(f'\\nThe tokenized sentence is:\\n{tokenized_sentence}')\n",
    "\n",
    "numericalized_sentence = bert_tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "print(f'\\nThe numericalized sentence is:\\n{numericalized_sentence}')\n",
    "\n",
    "# Print the IDs for the special tokens for the BERT model\n",
    "print(f'- The token ID for the special token [CLS] is: {bert_tokenizer.cls_token_id}')\n",
    "print(f'- The token ID for the special token [SEP] is: {bert_tokenizer.sep_token_id}')\n",
    "print(f'- The token ID for the special token [PAD] is: {bert_tokenizer.pad_token_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fd665",
   "metadata": {},
   "source": [
    "As the exampled indicates, we need to add the [CLS] and [SEP] tokens and tokenize each sentence of the text dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82dd7f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     [101, 2022, 4527, 2012, 2025, 2383, 2464, 2032...\n",
       "449    [101, 5689, 2013, 1996, 8514, 2065, 2008, 2003...\n",
       "475    [101, 2005, 2116, 2086, 2975, 2369, 2032, 1037...\n",
       "420    [101, 2062, 10433, 1998, 2062, 23626, 2084, 23...\n",
       "149    [101, 21862, 18277, 4741, 19080, 2005, 3053, 2...\n",
       "112    [101, 2004, 2016, 2253, 1999, 1998, 2246, 2061...\n",
       "388    [101, 2187, 2014, 9140, 2098, 2841, 18576, 210...\n",
       "61     [101, 2677, 1997, 1996, 5430, 1996, 16669, 663...\n",
       "10     [101, 1996, 2365, 1997, 2442, 9331, 3270, 1996...\n",
       "81     [101, 8116, 2033, 2013, 2023, 2173, 26090, 199...\n",
       "Name: numericalized_sentence, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the 100 special tokens to the numericalized sentences on the dataframe\n",
    "tokens_df['numericalized_sentence'] = tokens_df['numericalized_sentence'].apply(lambda x: [bert_tokenizer.cls_token_id] + x + [bert_tokenizer.sep_token_id])\n",
    "tokens_df['numericalized_sentence'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62b1d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 0 padding to the numericalized sentences on the dataframe\n",
    "tokens_df['numericalized_sentence'] = tokens_df['numericalized_sentence'].apply(lambda x: x + [bert_tokenizer.pad_token_id] * (max_len - len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1360e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348    76\n",
       "343    76\n",
       "120    76\n",
       "144    76\n",
       "201    76\n",
       "381    76\n",
       "18     76\n",
       "439    76\n",
       "77     76\n",
       "339    76\n",
       "Name: numericalized_sentence_length, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column that indicates the length of the numericalized sentences\n",
    "tokens_df['numericalized_sentence_length'] = tokens_df['numericalized_sentence'].apply(len)\n",
    "tokens_df['numericalized_sentence_length'] .sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb1ed282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(447,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the numericalized sentences from the dataframe\n",
    "numericalized_sentences = tokens_df['numericalized_sentence'].values\n",
    "numericalized_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2344b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row of the numericalized sentences to a list\n",
    "numericalized_sentences = [list(x) for x in numericalized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feeed5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the numericalized sentences is: (447, 76)\n",
      "[[  101 21862 18277 ...     0     0     0]\n",
      " [  101  2045  2320 ...     0     0     0]\n",
      " [  101  1037 23358 ...     0     0     0]\n",
      " ...\n",
      " [  101  2044  2023 ...     0     0     0]\n",
      " [  101  2002  4594 ...     0     0     0]\n",
      " [  101  2005  2116 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the list into a 2D NumPy array\n",
    "numericalized_sentences = np.array(numericalized_sentences)\n",
    "print(f'The shape of the numericalized sentences is: {numericalized_sentences.shape}')\n",
    "print(numericalized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "465072a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 21862, 18277,  ...,     0,     0,     0],\n",
      "        [  101,  2045,  2320,  ...,     0,     0,     0],\n",
      "        [  101,  1037, 23358,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2044,  2023,  ...,     0,     0,     0],\n",
      "        [  101,  2002,  4594,  ...,     0,     0,     0],\n",
      "        [  101,  2005,  2116,  ...,     0,     0,     0]], dtype=torch.int32)\n",
      "the shape of the numericalized tensor is: torch.Size([447, 76])\n"
     ]
    }
   ],
   "source": [
    "#  Convert the numpy array into a Tensor\n",
    "numericalized_sentences = torch.from_numpy(numericalized_sentences)\n",
    "print(numericalized_sentences)\n",
    "print(f'the shape of the numericalized tensor is: {numericalized_sentences.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c9431",
   "metadata": {},
   "source": [
    "### Discuss the following:\n",
    "* What whas the pipeline of this exercise?\n",
    "* A Summary of the data cleaning and preprocessing steps.\n",
    "* What is the difference between a token and a sentence?\n",
    "* Why did we converted the tokens to numbers?\n",
    "* Why did we add the special tokens?\n",
    "* What advantages offered Pandas for text manipulation?\n",
    "* Would this approach be suitable for complex datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52596f",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "* Repeat this pipeline with 3 different books that appear very different in nature (don't add the special tokens).\n",
    "* When you obtain the numericalized sentences, convert them into a long 1D Numpy array.\n",
    "* Plot the distribution of the numericalized tokens for each book using histograms.\n",
    "* Comment your experience during the next lesson."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bd52410ac2df406f4a7dd1b627ebb13ba3e371ebde73b2ddba1931965b1f80d"
  },
  "kernelspec": {
   "display_name": "unpackAIdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
